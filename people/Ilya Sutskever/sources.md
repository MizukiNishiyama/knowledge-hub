# Ilya Sutskever - 出典・参考リンク

> generated_at: 2026-02-25

## 一次情報

- [Safe Superintelligence Inc. 公式サイト](https://ssi.inc) - SSIの公式ページ・ミッション宣言
- [Wikipedia - Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever) - 経歴・業績の包括的情報
- [Wikipedia - Safe Superintelligence Inc.](https://en.wikipedia.org/wiki/Safe_Superintelligence_Inc.) - SSIの設立経緯・資金調達

## 主張の出典

1. **「アラインメントは汎化問題」**
   - [LessWrong - Ilya Sutskever's thoughts on AI safety (July 2023)](https://www.lesswrong.com/posts/TpKktHS8GszgmMw4B/ilya-sutskever-s-thoughts-on-ai-safety-july-2023-a) - アラインメント哲学の詳細な記録
   - [EA Forum - Ilya: The AI scientist shaping the world](https://forum.effectivealtruism.org/posts/THfXNTP6YdXnNge8P/ilya-the-ai-scientist-shaping-the-world) - 安全性研究への姿勢

2. **「感覚ある生命全体へのアラインメント」**
   - [The Neuron - Unpacking Dwarkesh's Ilya Sutskever Interview](https://www.theneuron.ai/explainer-articles/unpacking-dwarkeshs-ilya-sutskever-interview-on-agi-asi-and-how-to-build-both-safely) - 感覚ある生命への価値整合に関するインタビュー分析
   - [DEV Community - Ilya Sutskever's Vision: Safe Superintelligent AI](https://dev.to/frtechy/ilya-sutskevers-vision-safe-superintelligent-ai-17n2) - ビジョンの解説

3. **「安全性と能力は双子の課題」**
   - [Medium/Binary Bards - Why Ilya Sutskever Left OpenAI](https://binarybards.medium.com/why-ilya-sutskever-left-openai-to-build-safe-superintelligence-0d36d8c1c3f1) - SSI設立動機と安全性＝能力の同時追求思想

4. **「スケーリングの終焉と新パラダイム」**
   - [The AI Corner - Ilya Sutskever's New Playbook for AGI](https://www.the-ai-corner.com/p/ilya-sutskever-safe-superintelligence-agi-2025) - スケーリング限界論と新しいAGIアプローチ
   - [Analytics India Magazine - Ilya Sutskever Changes His Mind](https://analyticsindiamag.com/ai-news-updates/ilya-sutskever-changes-his-mind-about-how-to-build-superintelligence/) - 超知能構築の方法論転換

5. **「超知能は無限に安定した独裁を可能にする」**
   - [FAR.AI - Opening Remarks: Confronting the Possibility of AGI](https://www.alignment-workshop.com/sf-talks/ilya-sutskever-opening-remarks-confronting-the-possibility-of-agi) - AGIの存在論的リスクに関する講演

## 資本政策・事業関連

- [TechCrunch - SSI reportedly valued at $32B](https://techcrunch.com/2025/04/12/openai-co-founder-ilya-sutskevers-safe-superintelligence-reportedly-valued-at-32b/) - 320億ドル評価の報道
- [TechCrunch - Ilya Sutskever will lead SSI following CEO's exit](https://techcrunch.com/2025/07/03/ilya-sutskever-will-lead-safe-superintelligence-following-his-ceos-exit/) - Daniel Gross退社後のCEO就任
- [Calcalist - Ilya Sutskever breaks silence on OpenAI departure](https://www.calcalistech.com/ctechnews/article/sjp2u5oj11e) - OpenAI退社の真意
- [eWeek - SSI Hits $30 Billion Valuation Without a Product](https://www.eweek.com/news/ilya-sutskever-ai-startup-ssi-30b-valuation/) - 製品なしでの高バリュエーション分析
- [Inc. - OpenAI's Ilya Sutskever Raised Billions but Has No Product Plans](https://www.inc.com/ben-sherry/openai-co-founder-ilya-sutskever-safe-superintelligence-3-billion-no-product/91271937) - 収益なき資本調達の背景
