# Ilya Sutskever

> generated_at: 2026-02-25

## 1. 基本情報

- **人名**: Ilya Sutskever（イリヤ・サツキバー）
- **所属**: Safe Superintelligence Inc.（SSI）
- **役職**: CEO・共同創業者（元OpenAI共同創業者・主任研究員）
- **誕生年**: 1986年

## 2. ラベル（大分類）

- 研究者
- 起業家

## 3. 小ラベル（テーマ軸）

- 生成AI
- ソフトウェア
- 社会思想

## 4. 概要

安全な超知能の実現を目指す深層学習の先駆者

## 5. 詳細

Geoffrey Hinton門下でAlexNetを共同開発。OpenAI共同創業者として GPT・DALL-E等を主導。2024年に退社しSSIを設立、安全性と能力を同時に追求する超知能開発に着手。評価額320億ドル。

## 6. 行動原理（実現したい社会・信念）

- **根本信念**: 超知能は不可避であり、安全性を後付けではなく基盤から組み込む必要がある。安全性と能力は二律背反ではなく同時に追求すべき双子の課題
- **目指す社会**: 超知能が感覚ある生命全体（人間だけでなく）の利益に整合する世界。AIが雇用・疾病・貧困を解決しつつ、無限に安定した独裁や自律兵器を生まない社会
- **意思決定原理**: 商業化圧力より安全性研究を優先する。OpenAI退社の動機自体が「安全性への注力不足」への危機感に基づく
- **哲学的姿勢**: アラインメントを「汎化問題」として科学的に捉え、核安全保障に匹敵する制度設計が必要と主張

## 7. 興味深い主張

1. **「アラインメントは汎化問題」**: モデルが人間の価値観を堅牢に学習すれば、予測不能な逸脱は起きないという仮説。安全性を工学ではなく科学として捉える（sources.md #1）
2. **「感覚ある生命全体へのアラインメント」**: 人間だけでなく感覚を持つ全生命を対象にする方が、AI自身も感覚的存在であるため整合しやすいと主張（sources.md #2）
3. **「安全性と能力は双子の課題」**: 他社が能力→安全の順で開発するのに対し、SSIは両者を基盤から同時に追求するアプローチ（sources.md #3）
4. **「スケーリングの終焉と新パラダイム」**: 従来のスケーリング則に限界があると認識し、新たな学習パラダイムの必要性を示唆（sources.md #4）
5. **「超知能は無限に安定した独裁を可能にする」**: AIの正の側面（雇用・疾病解決）と負の側面（自律兵器・偽情報・独裁安定化）の両方を直視（sources.md #5）

## 8. 参考にできる点

- **「安全性＝基盤設計」フレーム**: 監査・ガバナンスを後付けでなく設計段階から組み込む思想は、AIプロダクト開発・制度設計の両方に直接応用可能
- **商業圧力への抵抗モデル**: SSIは「製品なし・収益なし」で320億ドル評価を獲得。純粋な研究ミッションで資本を集める戦略は、長期R&D型事業の資本政策として参考になる
- **アラインメント＝汎化問題という科学的フレーミング**: 安全性を倫理的議論ではなく技術的・科学的問題として定義し直すアプローチ。AIガバナンスの制度設計において、感情論を排した議論の枠組みとして有用
- **「感覚ある生命」への拡張**: 人間中心主義を超えた価値整合の設計思想。ポストAGI倫理やAI権利論を考える際の参照軸
- **退社という意思決定の一貫性**: OpenAIでの地位を捨ててでも信念を貫いた行動は、組織内で安全性を主張する際の覚悟の参照事例

## 9. 参考にすべきではない点

- **製品なしの超高バリュエーション**: 320億ドル評価は個人の評判・ネットワークに大きく依存。再現性が極めて低く、一般的な資本政策の参考にはならない
- **OpenAI退社劇の政治的文脈**: Altman解任→復帰→Sutskever退社という経緯は組織政治の要素が大きく、「安全性のための退社」という美談だけでは説明できない
- **AGIタイムラインの不確実性**: 「5〜20年以内」という幅の広い予測は、ポジション形成に影響された可能性がある
- **「感覚ある生命」概念の曖昧さ**: AI自身が感覚的存在であるという前提は未検証であり、哲学的にも論争的

---

### 関心クラスタ該当

| クラスタ | 該当 |
|---|---|
| 生成AI/LLM・エージェント・プロダクト化 | ◎ GPT・DALL-E・AlexNet開発、スケーリング限界論、SSIでの新パラダイム追求 |
| ガバナンス（制度設計・監査） | ◎ 核安全保障型のAI安全制度、安全性の基盤設計思想 |
| 事業（DX・M&A・資本政策） | ○ 製品なしで320億ドル評価、Meta買収拒否、研究ミッション型資本調達 |
| 思想（社会構造・ポストAGI） | ◎ 感覚ある生命へのアラインメント、超知能による独裁安定化リスク |
| カルチャー（音楽・スポーツ） | 該当なし |
